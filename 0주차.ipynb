{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능이란? \n",
    "## 왜 인공지능을 공부하나요? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신문 기사 \n",
    "- Data Scientist : The Sexiest Job of the 21st Century\n",
    "\n",
    "- Starting a Career in Artificial Intelligence\n",
    "\n",
    "직업 \n",
    "- Embedded AI : 작은 디바이스에 인공지능 집어 넣는 것 \n",
    "- Explainable AI : 인공지능의 장/단점은 해석이 안되는데 그것을 설명하는 직업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 사이언스 벤 다이어 그램 \n",
    "\n",
    "- 코딩\n",
    "- 수학 & 통계지식 \n",
    "- 도메인 전문성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터과학 인공지능 머신러닝 딥러닝\n",
    "Data Science $\\subset$ Field of Artificial Intelligence $\\subset$ Field of Machine Learning $\\subset$ Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 과학(Data Science)\n",
    "정형 또는 비정형 데이터로부터 \n",
    "\n",
    "지식과 인사이트를 추출하는데 \n",
    "\n",
    "과학적 방법론, 프로세스, 알고리즘, 시스템을 동원하는 융합분야 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공지능(Artificial Intelligence) \n",
    "컴퓨터가 사람의 지적 행동을 따라 할 수 있는 능력 \n",
    "\n",
    "학습, 추론, 인식, 계획, 자연어처리, 지각, 개체 조작 능력 문제 등을 다룸 \n",
    "\n",
    "- Vision \n",
    "    - Image Recognition \n",
    "    - Machine Vision \n",
    "- Language Processing(NLP) 자연어 \n",
    "    - Classification \n",
    "    - Translation \n",
    "    - Data Extraction \n",
    "- Speech \n",
    "    - Text to Speech \n",
    "    - Speech to Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝(Machine Learning) \n",
    "컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야 \n",
    "\n",
    "- ex) \n",
    "    - 데이터 X -> 함수f(지식) -> 현상 Y 를 통해 \n",
    "\n",
    "    - 새로운 데이터 -> 학습한 함수 -> 판단 을 실시한다.\n",
    "\n",
    "- 명시적 프로그램은 너무 많은 Rule을 필요로 함 \n",
    "- Arthur Samuel(1959) : 머신러닝이란 명시적으로 프로그램하지 않은 상태로 컴퓨터를 학습시키는 분야이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지도학습\n",
    "지도학습(Supervised learning) : learning with labeled examples\n",
    "- 1:1 mapping\n",
    "- cat,dog의 label을 붙여주고 학습\n",
    "\n",
    "#### 비지도학습\n",
    "비지도학습(Unsupervised learning) : learning with unlabeled data\n",
    "- User interests clustering (군집화) \n",
    "- Product items clustering (사용자가 구분방법 정의)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝(Deep Learning)\n",
    "사람의 신경망을 묘사한 인공신경망(Artificial neural network)에 기반하는 \n",
    "\n",
    "머신러닝 알고리즘의 한 종류 \n",
    "- GPT3 모델 : 현재 나온 제일 큰 인공신경망(1300만개), 사람은 몇 조개를 가지고 있음\n",
    "\n",
    "Black box \n",
    "- 분석이 잘 되긴하는데 왜 잘되는지는 아직 알지 못함 \n",
    "\n",
    "Perceptron \n",
    "- 뉴런과 유사하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional Machine Learning  VS  Deep Learning \n",
    "- 기존 기계학습 : 특징 추출을 위해 사람이 직접 데이터를 가공해야 했음\n",
    "- 딥러닝 : 별도의 데이터 가공 없이 오직 데이터에 기반하여 End-to-End로 학습 가능 \n",
    "\n",
    "Traditional Machine Learning \n",
    "- 전문가에 의한 특징 추출의 한계\n",
    "\n",
    "Deep Learning \n",
    "- 기계가 모든 특징을 추출, 정보를 구분할 수 있는 최소단위 입력만으로 학습(영상 픽셀, 음성 신호 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능의 역사 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1956년 AI 탄생 \n",
    "\n",
    "앨런 튜링 - 1950년 튜링 테스트 창시(채팅하는 상대가 컴 or 사람 알아내지 못하면 통과) \n",
    "\n",
    "다트머스 회의 - 1956년 존 메카시 \"인공지능\" 언급\n",
    "\n",
    "---\n",
    "\n",
    "2. 1956 ~ 1974 AI 1차 붐 \n",
    "\n",
    "다트머스 회의 이후 인공지능 관심 급증 \n",
    "\n",
    "Perceptron 등장 -> 간단한 문제 해결 \n",
    "\n",
    "튜링 테스트를 통과한 최초의 챗봇 ELIZA 등장 \n",
    "\n",
    "---\n",
    "\n",
    "3. 1974 ~ 1980 AI 1차 겨울 \n",
    "\n",
    "모라벡의 역설 \n",
    "- 인간에게 쉬운 일은 컴퓨터에게 어렵고, 인간에게 어려운 일은 컴퓨터에게 쉽다. \n",
    "\n",
    "상식의 저주 \n",
    "- 기계는 너무 당연한 상식조차 모두 가르쳐야 한다. \n",
    "\n",
    "마빈 민스키 \n",
    "- Perceptron의 한계를 수학적으로 증명 \n",
    "\n",
    "---\n",
    "\n",
    "4. 1980 ~ 1987 AI 2차 붐 \n",
    "\n",
    "전문가 시스템 \n",
    "- 보편적인 인공지능을 만들기 어려움을 인정\n",
    "- 특정 분야에 많은 데이터가 있으면 해당 분야에서 인공지능 전문가가 됨\n",
    "\n",
    "Multi layer Pereptron\n",
    "- Perceptron의 한계를 뛰어 넘음 \n",
    "- 한 층의 perceptron을 여러 겹 쌓으면 어려운 문제도 풀 수 있음 \n",
    "- 여러 데이터를 이용한 '학습'의 개념이 등장 \n",
    "\n",
    "Back Propagation\n",
    "- Multi layer perceptron을 학습시키기 위한 학습 방법론 등장 \n",
    "   \n",
    "---\n",
    "\n",
    "5. 1987 ~ 1993 AI 2차 겨울 \n",
    "\n",
    "전문가 시스템에 대한 실망 \n",
    "- 입력한 데이터 이외의 것에는 활용 불가 \n",
    "- 모라벡의 역설, 상식의 저주의 재조명 \n",
    "\n",
    "학습의 한계 \n",
    "- 충분히 학습시키기 위한 데이터의 부족 \n",
    "- Multi layer perceptron과 Back propagation을 가속화 할 컴퓨터 파워의 부족 \n",
    "\n",
    "---\n",
    "\n",
    "6. 1993 ~ 2011 AI 3차 붐 \n",
    "\n",
    "컴퓨팅 파워의 증가(무어의 법칙) \n",
    "- 1997년 세계 체스 챔피언(IBM의 Deep Blue)\n",
    "- 2011년 제퍼디 퀴즈 쇼 우승(IBM의 Watson) \n",
    "\n",
    "---\n",
    "\n",
    "7. 2011 ~ 현재 AI 붐의 연속 \n",
    "\n",
    "빅데이터, 딥러닝, GPU 병렬 컴퓨팅 -> 2016년 세계 바둑 챔피언 대국(알파고 vs 이세돌) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI 4대 천왕 \n",
    "- 제프리 힌튼(구글 자문)\n",
    "    - 30년 이상 공부, BackPropagation 처음 고안 \n",
    "- 요수아 벤지오 (IBM, 구글 공동 연구)\n",
    "    - (자연어처리 부문 연구)\n",
    "- 얀 르쿤(페이스북 자문)\n",
    "- 앤드류 응(구글, 바이두 자문)\n",
    "    - 코세라 => Deep Learning 교육"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능의 활용 사례 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 응용 분야 - Computer Vision \n",
    "\n",
    "- 이미지 분류 (Image classification) \n",
    "- 사물 검출 (Object detection) \n",
    "- 분할 (Segmentation) \n",
    "\n",
    "ex) \n",
    "\n",
    "- Naver corp.AutoCam, 생체 인증에 Computer Vision 기술 활용\n",
    "- Visual Question Answering(VQA) \n",
    "    - 이미지를 이해하고 주어지는 질문에 답변"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network(GAN)\n",
    "Ian Goodfellow, 2014 \n",
    "- 새로운 데이터를 생성하는 생성자(generator)와 이 데이터를 평가하는 구별자(discriminator)가 서로 대립하여 각각의 성능을 높이는 목적을 달성\n",
    "- Generator vs Discriminator 서로 대립하며 성능을 높임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 응용 분야 - Natural Language Processing\n",
    "Chat bots \n",
    "- 개인비서, 대화형 커머스 등에 활용\n",
    "\n",
    "News article generation\n",
    "- 뉴스 기사 생성\n",
    "\n",
    "Open AI GPT 시리즈 \n",
    "- 몇 개 키워드만 넣으면 작문을 작성해주는 알고리즘\n",
    "\n",
    "Q & A systems(질의 응답 시스템)\n",
    "- 구글홈, 시리\n",
    "\n",
    "기계 번역 \n",
    "- 파파고를 이용한 외국어 자동 번역(한국어 -> 영어) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 응용 분야 - Multi-modal \n",
    "Computer Vision + Nature Language Processing\n",
    "\n",
    "Image Captioning\n",
    "- 사진이 해석해서 글을 만들어 냄 \n",
    "\n",
    "Pre-trained CNN \n",
    "- NIC가 성공적으로 작동하는 이유는 ImageNet이라는 엄청난 크기의 이미지 분류 데이터로 사전 학습을 시키기 때문(언어모델도 마찬가지) \n",
    "- Caption을 생성하는 것을 배우기 전 이미지와 언어에 대한 기본지식을 배움 (이미 성공한 이미지 + 텍스트 학습)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 분류 \n",
    "- Supervised \n",
    "- Unsupervised\n",
    "- Reinforcement(강화학습) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강화학습 \n",
    "- 어떤 상황에서 어떤 행동을 취하였는가? \n",
    "- 보상을 얼마나 받았는가? \n",
    "    - 어떤 행동을 해야 보상을 많이 받는가 학습함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "알파고 \n",
    "- 사람기보 -> 사전학습 -> (알파고1~알파고100만) 자체경쟁\n",
    "\n",
    "알파고 Zero\n",
    "- 사람의 기보를 보지않고 스스로 증식하여 학습"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
