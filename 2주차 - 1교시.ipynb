{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process of Learning \n",
    "1. Evaluation(Forward propagation)\n",
    "2. Loss and Gradient(Backpropagation)\n",
    "\n",
    "\n",
    "- Loss : 얼만큼 틀렸다\n",
    "- Gradient : 어느방향으로 너가 가야해 \n",
    "\n",
    "\n",
    "3. Update (SGD)\n",
    "\n",
    "\n",
    "- Update : 딥러닝 모형을 바꾸는 optimizer\n",
    "- SGD : optimizer의 대표적 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력과 Loss는 w들의 결과로 나온 값\n",
    "    - 적절한 w들은 낮은 Loss를 만들어냄\n",
    "    - 적절하지 않은 w들은 높은 Loss를 만들어 냄 \n",
    "- Loss를 바탕으로 각각의 w 하나 하나가 얼마나 영향을 주었는지 알아내고 좀 더 적절한 방향으로 w들을 변경해 나가는 것을 Back-propagation 이라 함 \n",
    "- Loss를 기반으로 weight 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient decent(경사 하강법)\n",
    "임의의 한 지점으로부터 시작해, loss가 줄어드는 방향으로 w(weights = parameters)들을 갱신(loss가 가장 적어질 때까지)\n",
    "![title](images/Gradient_decent.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목표 지점의 방향은 어떻게 알 수 있을까? \n",
    "- 발에 집중해 아래쪽으로 기울여 방향을 찾음 \n",
    "\n",
    "그 방향으로 얼만큼 움직여야 하는가? \n",
    "- 한 발짝 한 발짝\n",
    "\n",
    "기울어진 방향으로 한 발짝 만큼 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss가 줄어드는 방향은  어떻게 알 수 있을까? \n",
    "    - 미분을 이용 $\\frac{dE}{dw_{i}}$\n",
    "    - 그래프 상에서 기울어진 방향 찾기 => 미분 이용\n",
    "\n",
    "\n",
    "2. 그 방향으로 얼만큼 움직여야 하는가? \n",
    "    - Learning rate($\\varepsilon$) \n",
    "    - ex) 경사가 기울어진 방향으로 한발자국 씩\n",
    "\n",
    "3. [Loss의 미분값] x [learning rate] 만큼 parameter(w_{i})들을 수정\n",
    "    - ex) w_{1} -> w_{2} -> ....  w_{100} -> ....w_{i}\n",
    "\n",
    "4. Learning rate가 작으면 최저점을 찾는 과정이 매우 더딤 \n",
    "    - ex) 학습을 for문을 통해서 하는데, 최적점에 도달하지 못할 수 도 있음\n",
    "- Learning rate이 크면 최저점을 찾지 못할 수 있음 \n",
    "    - ex) 값이 무한대로 튈 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다루는 데이터(모델,합,양)에 따라 적절한 Learning rate가 다름 \n",
    "- 0.1 부터 시작 => 0.01... 최소 10번은 해봄 try error로 찾아감!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{1}^{t+1} = w_{1}^{t} - \\varepsilon\\frac{dE}{dw_{1}}$\n",
    "- 뒤에 수식이 -인 이유 : 기울기가 있는 것의 반대방향으로 가기 위하여\n",
    "-  E = 모든 훈련 샘플에 대하여 계산되는 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임의의 한 지점으로부터 시작해, loss가 줄어드는 방향으로 w(weights = parameters)들을 갱신(loss가 가장 적어질 때까지)\n",
    "- w을 음의 기울기 방향(-)으로 조금씩 움직이는 것을 여러 번 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global minimum, Local minimum\n",
    "- 항상 G M 으로 가야 하나? \n",
    "    - No!  Lcal minimum로 찾아가도 괜찮음, 딥러닝은 복잡하고, 실제로 큰 차이가 없음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-Propagation \n",
    "\n",
    "- Forward 과정을 통해 나온 Loss에 각 w들이 끼친 영향을 알기 위해서는 전체 Loss를 각각의 w로 편미분 해야 함 \n",
    "    - $\\frac{dLoss}{dw_{i}} = \\frac{dE}{dw_{i}}$\n",
    "- 하지만 Loss를 직접적으로 w에 대해 미분 하기란 쉽지 않음\n",
    "    - Ex) 입력2 / 출력1, 단층 퍼셉트론의 경우 MSE Loss는 다음과 같음 \n",
    "    - $(1-\\frac{1}{1+e^{-(w_{1}x_{1}+w_{2}x_{2}+b)}})^{2}$\n",
    "    - MSE 이런 단순한 것도 복잡한 식이 나옴 \n",
    "- 입,출력이 조금 더 많거나, 퍼셉트론이 다층일 경우 계산은 더욱 복잡 \n",
    "- 첫번째 인공지능의 겨울을 가져온 이유 중 하나 \n",
    "- 해결법 : Chain Rule을 이용한 Back-propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our Goal \n",
    "    - $\\frac{dLoss}{dw_{i}}$\n",
    "- Chain Rule\n",
    "    - $\\frac{dLoss}{dw_{i}} = \\frac{dLoss}{dz} \\frac{dz}{dw_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-Propagation on PyTorch : autograd \n",
    "- 딥러닝 모델(네트워크)은 매우 많은 연산을 통해 결과를 도출함 \n",
    "- 하지만 그 연산들을 잘게 쪼개면 더하기,곱하기,나누기,지수연산으로 이루어짐 \n",
    "- Chain Rule은 복잡한 연산을 나누어 미분 \n",
    "- 결국 3가지(+,*,/)operation의 미분 과정만 알면 목적인 $\\frac{dLoss}{dw_{i}}$를 알 수 있음\n",
    "    - 지수가 없는 이유 : 미분을 해도 값이 똑같기 떄문\n",
    "- 실제 pytorch와 다른 딥러닝 프레임워크에서도 이러한 방식으로 back-propagate를 진행 \n",
    "    - Pytorch에서는 이를 autograd라고 함\n",
    "- 미분이 안되면 B.P 불가능! \n",
    "    - 그런 것 들을 이런 공부를 통해 미리 알 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Sum\n",
    "x = 10, y = 5, z = 15\n",
    "\n",
    "z = x + y , \n",
    "$\\frac{dz}{dx} = 1$ , $\\frac{dz}{dy} = 1$\n",
    "\n",
    "$\\frac{dL}{dx} = \\frac{dL}{dz} * \\frac{dz}{dx} = \\frac{dL}{dz} * 1$\n",
    "- ex) $\\frac{dL}{dx}$ = 1.3 *1 = 1.3\n",
    "\n",
    "$\\frac{dL}{dy} = \\frac{dL}{dz} * \\frac{dz}{dy} = \\frac{dL}{dz} * 1$\n",
    "- ex) $\\frac{dL}{dy}$ = 1.3 *1 = 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Multiply \n",
    "x = 10, y = 5, z = 50\n",
    "\n",
    "z = xy , \n",
    "$\\frac{dz}{dx} = y$ , $\\frac{dz}{dy} = x$\n",
    "\n",
    "$\\frac{dL}{dx} = \\frac{dL}{dz} * \\frac{dz}{dx} = \\frac{dL}{dz} * y$\n",
    "- ex) $\\frac{dL}{dx}$ = 1.3 * 5 = 6.5\n",
    "\n",
    "$\\frac{dL}{dy} = \\frac{dL}{dz} * \\frac{dz}{dy} = \\frac{dL}{dz} * x$\n",
    "- ex) $\\frac{dL}{dy}$ = 1.3 * 10 = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Division\n",
    "x = 10, z = 1/10\n",
    "\n",
    "z = 1/x , $\\frac{dz}{dx} = -\\frac{1}{x^{2}}$\n",
    "\n",
    "$\\frac{dL}{dx} = \\frac{dL}{dz} * \\frac{dz}{dx} = \\frac{dL}{dz} * \\frac{1}{x^{2}}$ \n",
    "- ex) $\\frac{dL}{dx} = 2 * -(\\frac{1}{10})^{2})$ = -0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제\n",
    "$\\varepsilon = 0.1$, w = -2, x = 5, b = 3\n",
    "\n",
    "f = wx + b , g = w * x ,  f = g + b\n",
    "\n",
    "$\\frac{dg}{dw} = 5, \\frac{df}{dg} = 1$\n",
    "\n",
    "$\\frac{df}{dw} = \\frac{df}{dg} * \\frac{dg}{dw} = 1 * 5 = 5$\n",
    "\n",
    "$ w = w - \\varepsilon \\frac{dL}{dw} = w - \\varepsilon \\frac{df}{dw} = -2  - (0.1 * 5) = -2.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [참고]Back-Propagation(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{1}{1+e^{-x}}$가 만들어지는 과정은 다 나눠서 이루어진다. \n",
    "\n",
    "x * -1 = -x -> -x exp -> $e^{-x}$ + 1 -> 1 + $e^{-x}$ /  -> $\\frac{1}{1+e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{dL}{dy}y^{2}exp^{-x} = \\frac{dL}{dy}\\frac{1}{(1+e^{-x})^{2}}e^{-x}$\n",
    "\n",
    "$\\frac{dL}{dy}\\frac{1}{1+e^{-x}}\\frac{e^{-x}}{1+e^{-x}}$\n",
    "\n",
    "$\\frac{dL}{dy}\\frac{1}{1+e^{-x}}(1-\\frac{1}{1+e^{-x}})$\n",
    "\n",
    "-> $\\frac{dL}{dy}y(1-y)$\n",
    "- 다 나누지 않고 편리하게 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_(self):\n",
    "    self.out = None\n",
    "    \n",
    "def forward(self, x): \n",
    "    out = sigmoid(x)\n",
    "    self.out = out\n",
    "    return out\n",
    "\n",
    "def backward(self,dout):\n",
    "    dx = dout * (1.0 - self.out)*self.out    # dout 뒤에서온 미분값, self.out 나자신\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜, 시간 : epoch : 1 |loss 10.925624\n",
      "날짜, 시간 : epoch : 2 |loss 4.139618\n",
      ".....loss가 점점 줄어듬\n"
     ]
    }
   ],
   "source": [
    "# Back propagation를 활용한 Loss 감소 예시 \n",
    "print(\"날짜, 시간 : epoch : 1 |loss 10.925624\")\n",
    "print(\"날짜, 시간 : epoch : 2 |loss 4.139618\")\n",
    "print(\".....loss가 점점 줄어듬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "- Back propagation을 통해 weights(= parameters)을 업데이트 시키는 방법\n",
    "- 학습의 안전성 및 효율성을 위해 여러 Optimization 기법들이 제안됨 (실제로 update를 진행시키는 과정)\n",
    "    - Stochastic Gradient Decent(SGD) \n",
    "    - AdaGrad\n",
    "    - RMSProp\n",
    "    - Momentum \n",
    "    - Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient decent(SGD)\n",
    "\n",
    "- Stochastic : 확률적인\n",
    "- Batch learning과 달리 샘플 일부만을 사용하여 파라미터를 업데이트 하는 방법\n",
    "- 빠른 학습 가능, local minimuma에 빠질 위험이 적음 \n",
    "- 노이즈 데이터로 인해 변동이 큼 \n",
    "- Epoch마다 무작위로 샘플을 선택하면 그 효과를 극대화 할 수 있기 때문에 Stochastic Gradient decent라 부름\n",
    "    - 1Epoch : 전체 데이터를 훑었다.\n",
    "\n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\frac{dE_{t}}{dw_{1}}$\n",
    "    - $\\frac{dE_{t}}{dw_{1}}$ -> 일부 샘플에 대해 계산한 오차 함수의 기울기\n",
    "    \n",
    "- 첫번째 방식으로 다 훑으면(1Epoch) -> 새로운 랜덤방식으로 샘플을 나누고 진행(2Epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Learning(Epoch Learning)\n",
    "- 데이터를 합쳐서 다 넣고! 계산 실시\n",
    "- 전체 훈련 데이터를 사용 \n",
    "- 대규모 데이터 셋에 적용하기 힘듬\n",
    "- 데이터 구성이 항상 같기 때문에 local minima에 빠질 위험이 있음 \n",
    "    - LM에 빠져도 상관은 없지만, 빠지게 두는 건 x\n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\frac{dE}{dw_{1}}$\n",
    "    - $\\frac{dE}{dw_{1}}$ -> 전체 샘플에 대해 계산한 오차 함수의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch \n",
    "- 몇 개의 샘플을 하나의 작은 집합으로 묶은 집합 단위로 가중치를 업데이트(SGD) \n",
    "- 복수의 샘플을 묶은 작은 집합을 미니배치((mini-batch)라고 함 \n",
    "    - 미니배치 크기는 얼마나? -> GPU 한계, 데이터 양, ... 요소 고려  보통 10~100개로 지정\n",
    "\n",
    "- $E_{t} = \\frac{1}{N_{t}} \\sum_{n\\subset D_{t}}E_{n}$\n",
    "    - $D_{t}$는 한 개의 미니배치를 나타내며 보통 10~100개의 샘플로 이루어짐\n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\frac{dE_{t}}{dw_{1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치러닝 => 잘되긴 하는데 너무 느림\n",
    "\n",
    "Stochastic Gradient Decent(SGD) => 시간 단축가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch, Batch size, Iterations\n",
    "Ex) MNIST data\n",
    "- number of training data = 60000\n",
    "- Let's take batch size of B = 100 \n",
    "- How many iteration in each epoch? 60000/100 = 600   \n",
    "    - 1 epoch = 600 iteration \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad \n",
    "- 개별 가중치에 적응적으로(adaptive) 학습률을 조정하면서 학습을 진행\n",
    "- 현재까지 따라서 많이 갱신된 가중치는 학습률이 낮아짐\n",
    "- 즉, 학습률 감소가 개별 가중치 마다 다르게 적용\n",
    "    - '많이 바뀐애는 조금 바뀌고' '조금 바뀐애는 많이 바뀌게'\n",
    "- h = h + $\\frac{dE}{dw_{1}}^{2}$ \n",
    "    - $\\frac{dE}{dw_{1}}^{2}$ : 1보다 크면 제곱시 값이 커짐\n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\frac{1}{\\sqrt h} \\frac{dE_{t}}{dw_{1}}$\n",
    "    - $\\frac{1}{\\sqrt h}$ 많이 갱신된 가중치는 적게 영향을 받게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "- AdaGrad의 단점을 해결하기 위한 방법 \n",
    "- AdaGrad의 식에서 gradient의 제곱값을 더하는 방식이 아니라 지수평균으로 대체 \n",
    "- Gradient가 무한정 커지는 것을 방지 \n",
    "- h = rh + (1-r)$\\frac{dE}{dw_{1}}^{2}$ \n",
    "    - r : 0 ~ 1\n",
    "    - 1-r : 무한정 커지는 것을 방지\n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\frac{1}{\\sqrt h} \\frac{dE_{t}}{dw_{1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum, Adam\n",
    "- 가중치의 업데이트 값에 이전 업데이트 값의 일정 비율을 더해줌 \n",
    "    - 즉, Gradient decent를 통해 이동하는 과정에 관성을 주는 것 (관성을 생각하면 됨)\n",
    "- Adam : AdaGrad(RMSProp)와 Momentum을 융합한 기법\n",
    "    - 기존에 바뀌던걸 덜 바뀌게 하면서 관성을 준게 Adam 이구나!\n",
    "    \n",
    "- $w_{1}^{t+1} = w_{1}^{t} - \\varepsilon \\bigtriangledown E_{t} +  \\mu \\Delta w^{t-1}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어떤걸 사용 \n",
    "1. Adam 써라 \n",
    "2. 안되면 SGD \n",
    "3. 둘다 안되면 optimizer 문제가 아닌 경우가 많음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
